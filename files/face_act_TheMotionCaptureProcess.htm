<!DOCTYPE html>

<!-- saved from url=(0024)http://docs.autodesk.com -->
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <meta name="product" content="SI">
      <meta name="release" content="2015">
      <meta name="book" content="GeneralUser">
      <meta name="created" content="2014-03-26">
      <meta name="topicid" content="GUID-2A7B7B4A-5EEF-499F-BB8A-1E0D048C53C8">
      <meta name="indexterm" content="Face Robot: motion capture (mocap) animation">
      <meta name="indexterm" content="motion capture: in Face Robot">
      <meta name="topic-type" content="concept">
      <title>The Motion Capture Process</title>
      <link rel="stylesheet" type="text/css" href="../style/softimage.css"><script type="text/javascript" src="../scripts/ac_common.js"></script><script type="text/javascript" src="../scripts/utils/adsk.redirect.js"></script></head>
   <body height="100%">
      <div class="body_content" id="body-content"><span class="anchor_wrapper"><a name="GUID-2A7B7B4A-5EEF-499F-BB8A-1E0D048C53C8"></a></span><div class="head">
            <h1>The Motion Capture Process</h1>
         </div>
         <div class="bodyProcess">
            <p><span class="anchor_wrapper"><a name="GUID-305249F1-FD43-44C1-A69B-E12D904FC424"></a></span>The human face has a finite number of useful landmarks to capture. The areas between
               these landmarks are only reacting to the movement of these points, albeit in a very
               complex manner. Face Robot is particularly useful for motion capture animation because
               it requires only a small number of facial capture markers (~32) to achieve high quality
               results. 
            </p>
            <p><span class="anchor_wrapper"><a name="GUID-2668F565-9D53-469F-8FE1-797FAF7C7D13"></a></span>When you're doing the motion capture session, you simply place markers on the critical
               areas of the actor's face. Then in Face Robot, you tune the soft tissue to accurately
               move the face in response to the captured motion. The results are more subtle movements
               and believable animation, all facets of which are controllable by you after the capture
               session has ended. 
            </p>
            <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-001B"></a></span> 
               <h2><span class="anchor_wrapper"><a name="GUID-E2A95295-72A9-4879-B5EB-F36100EACC9D"></a></span>Overview of Motion Capture Workflow
               </h2> 
               <p><span class="anchor_wrapper"><a name="GUID-532C346D-0B23-425B-A2A0-1304DCA83A7F"></a></span>Here's a basic overview for working with motion capture in Face Robot, from capturing
                  the mocap data to working with it in Face Robot. 
               </p> <span class="anchor_wrapper"><a name="GUID-651C9121-E5C3-4434-92B7-4C3385124E2C"></a></span><ol type="1" start="1">
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-D0DCB747-B955-45F1-A5A0-5F0732018107"></a></span>Place the mocap markers on the face of the actor. 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-E5EF3E4F-B618-4BA1-AAA2-5E1B58F6D560"></a></span>Face Robot is driven by 32 control points called the <span class="char_link"><a href="face_act_WhatsontheActPanel.htm#WSF468A8297860DD449B69C7615D16EBA9-0006">Animation Control Set</a></span>. These control points can be driven directly by motion capture data, so the motion
                        capture marker placement is related closely to the positions of animation control
                        set. 
                     </p> 
                     <div class="figure-anchor"><img src="../images/GUID-A26595AF-BA29-49E2-A820-4968A51F08D4-low.png"></div> 
                     <p><span class="anchor_wrapper"><a name="GUID-CC2EFCF5-AC33-422D-96A9-771049588396"></a></span>If you place the markers on the actor's face as shown in the following image, the
                        mocap data that you capture will match perfectly with the animation controls on the
                        head in Face Robot. 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-3AF9F424-CB30-4BF1-9178-FFC276B8FBA5"></a></span>Make sure to name the markers with an appropriate naming convention that maps to Face
                        Robot (see <span class="char_link"><a href="face_act_WhatsontheActPanel.htm#WSF468A8297860DD449B69C7615D16EBA9-0006">Animation Control Set</a></span>). 
                     </p> 
                     <div><span class="anchor_wrapper"><a name="GUID-A03E6693-3BC2-4DD7-988E-3D78D116FEA5"></a></span><div class="note-note"><span class="label">NOTE:</span>Forehead markers must be placed on the rigid head cap on the actor. 
                        </div>
                     </div> 
                     <div class="figure-anchor"><img src="../images/GUID-F5B1A74B-3D8C-4C31-A16D-221B985C188D-low.png"></div> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-5A9155F2-3844-49BF-82D6-526007F21DA3"></a></span>Record the desired facial mocap expressions. 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-D332265D-12A2-4959-B59C-1CD83072B58A"></a></span>Make sure to take the important poses: base, key, extreme expressions, range of movement,
                        standard expressions, and lip-sync visemes (visual phonemes). 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-B22D0607-0D75-426E-A29C-5CBA488D1C64"></a></span>The expressions you need to capture obviously depend on the performance that is required
                        for the project. However, experience has shown that at least the following captures
                        should be made to facilitate tuning of the head in Face Robot: 
                     </p> <span class="anchor_wrapper"><a name="UL_ACACA548E67B46269B5FF39FB77BA712"></a></span><ul>
                        <li> 
                           <p><span class="anchor_wrapper"><a name="GUID-0CCC6701-2EEC-4BB3-ACA8-64AA3038405D"></a></span>Base or zero pose: There should be a capture of a facial expression that corresponds
                              to the rest pose 3D scan. The actor's face should be in a pose with eyes open, mouth
                              closed, and expressionless. This simplifies the retargeting in the same way a T-pose
                              is used for a default body pose in character animation. 
                           </p> 
                        </li>
                        <li> 
                           <p><span class="anchor_wrapper"><a name="GUID-46FD2075-9F5B-4193-875E-3F795B539022"></a></span>Range of motion: The range of motion should exercise the widest possible range of
                              facial deformations, from smiles to screams to frowns and sneers. 
                           </p> 
                           <div class="figure-anchor"><img src="../images/GUID-E7B0BEB7-4CCA-46C5-A763-36AB2483F934-low.png"></div> 
                        </li>
                        <li> 
                           <p><span class="anchor_wrapper"><a name="GUID-7F04E8C6-8618-4816-A69E-DC0A3DCC7FB6"></a></span>Key poses: In particular for 3D scanned heads, it is also useful to capture additional
                              key poses because they make it easier to align the motion capture data with the facial
                              model. This can be done either as part of the range of motion or in separate takes.
                              
                           </p> 
                        </li>
                     </ul> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-341D6384-446B-483D-B60E-C122C85F28C1"></a></span>Clean up and filter the data, saving it as C3D data. This format is a standard optical
                        marker-based file format used predominantly for facial capture. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-8800BB04-EDBD-46D9-9F5E-D4A434CA03C8"></a></span>Organize the mocap data into separate folders for each capture session. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-43508471-FDAE-4E56-B118-3AD6B1B7241B"></a></span>In Face Robot, prepare the mocap data from each mocap session for the face in Face
                        Robot. This involves loading the zero (base) pose C3D file into Face Robot and creating
                        name and face map files. See <span class="char_link"><a href="face_act_PreparingMotionCaptureDataforRetargeting.htm">Preparing Motion Capture Data for Retargeting</a></span> for more information. 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-FF69BBD8-0C58-4F4A-8A41-99F8374F17B0"></a></span>Once you've done this, the mocap data is ready to be used at any time and on any character
                        in Face Robot. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-15750040-A03F-470C-852E-F441B13D1C8F"></a></span>Apply the mocap data to the animation controls on the face in Face Robot, including
                        static poses (see <span class="char_link"><a href="face_act_ApplyingRetargetedMotionCaptureData.htm">Applying Motion Capture Data</a></span>). 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-4AEBDCD0-0566-4F10-AB29-2A5B00A4E5B3"></a></span>Retarget the mocap data to the face in Face Robot by adjusting and calibrating it.
                        You can also set offsets on the animation controls on top of the mocap data and then
                        bake the results into plotted fcurves. 
                     </p> 
                     <p><span class="anchor_wrapper"><a name="GUID-3EFA719A-AEEA-4D52-9AF5-0221572A76B8"></a></span>See <span class="char_link"><a href="face_act_CalibratingtheMocapData.htm">Calibrating the Mocap Data</a></span>, <span class="char_link"><a href="face_act_AdjustingtheRetargetedMocapData.htm">Adjusting the Retargeted Mocap Data</a></span>, <span class="char_link"><a href="face_act_AddingOffsetstotheMocapData.htm">Adding Offsets to the Mocap Data</a></span>, and <span class="char_link"><a href="face_act_PlottingtheMocapandKeyframeData.htm">Plotting (Baking) the Mocap and Keyframe Data</a></span>. 
                     </p> 
                  </li>
               </ol> 
            </div>
            <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-001F"></a></span> 
               <h2><span class="anchor_wrapper"><a name="GUID-AAF52C25-345F-418A-8E7B-F5A4545DF336"></a></span>Tips for Doing Mocap for Face Robot
               </h2> <span class="anchor_wrapper"><a name="UL_A4DC1E4A430A4E379107143CDE1C256A"></a></span><ul>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-9714588A-4E06-4728-ABB6-7493C3D03947"></a></span>The placement of the stabilization markers is important. The nose bridge marker must
                        be placed such that its movement relative to facial expressions like "scrunching"
                        the nose is minimal. Likewise, the left and right forehead markers must be placed
                        in such a way that their movement relative to eyebrow motions is minimal. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-B390AA2D-B766-4B6E-8885-BDB6F21E4DC9"></a></span>Keep the shoulders steady: The two motion capture markers driving the neck tendons
                        in the animation controls are also influenced by movements in the shoulders, such
                        as when the actor's arms are raised above the head. In an ideal scenario, the actor
                        will sit in a chair with a relatively motionless body posture and emotional acting
                        focused on head movement and facial expressions. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-3089794A-6572-4CC3-9A3F-2C61EC92E1A2"></a></span>One actor, one set of markers: Save all C3D files in one session with the same actor
                        and markers. Then when you're retargeting the data, you only need to create one name
                        map and one face map to apply to all C3D files taken in that session. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-179BBF30-0634-4A42-A8EB-19EB06161A41"></a></span>Facial scans with mocap markers: To help you figure out which marker is which when
                        you load the C3D file into Face Robot to create a name map, you should take a scan
                        of the actor with the markers to act as a reference. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-45AA2551-9272-43E4-8EB4-5C0F2C381905"></a></span>To speed up interaction, press F6 and select <span class="MenuCascade" id="GUID-12584ACF-55E2-4BFA-B9AE-739D92E75D55">Toggle Face</span>. You can quickly scrub to the frame of the reference video that you want to work
                        on and then click <span class="MenuCascade" id="GUID-7C76B7E5-D311-4DCE-A68E-11B1CF7BDC51">Toggle Face</span> again. 
                     </p> 
                  </li>
                  <li> 
                     <p><span class="anchor_wrapper"><a name="GUID-8E21A786-A6EA-4CE3-81FC-B44554A1DF4A"></a></span>To make a preview, click on the camera icon at the top of the viewport and choose
                        <span class="MenuCascade" id="GUID-34D12665-639E-4DBC-9338-DE325A9EB2FA">Start Capture</span>. This creates a flipbook (playblast) using whatever view mode is shown in that viewport.
                        
                     </p> 
                  </li>
               </ul> 
               <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-0020"></a></span> 
                  <h3><span class="anchor_wrapper"><a name="GUID-75EF565A-A8C2-46DE-8043-FA92089F7286"></a></span>Adjusting the Mocap
                  </h3> <span class="anchor_wrapper"><a name="UL_A8F45110F80C485E9A74A4A732FBCEDB"></a></span><ul>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-2BB09C85-06ED-421E-9B76-048B3A70B6DD"></a></span>You can control the amount of motion coming from each mocap marker by choosing <span class="MenuCascade" id="GUID-D7D19247-A7E9-4EE4-972F-11E72B4C84B9">Adjust</span> from the Tools tab on the Act panel. 
                        </p> 
                     </li>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-4D72DEBB-2C4B-400E-B6AF-617E1B2E6890"></a></span>Make sure that the <span class="MenuCascade" id="GUID-96A3F2DB-19CA-4263-A7D1-A23811AD92E0">Head Controls <img src="../images/ac.menuaro.gif"> Enable Rotation</span> option is not selected for stabilized motion. 
                        </p> 
                     </li>
                  </ul> 
                  <p><span class="anchor_wrapper"><a name="GUID-56DD03D1-E2A4-4ABE-A82F-D946FB2FB2AC"></a></span>See <span class="char_link"><a href="face_act_AdjustingtheRetargetedMocapData.htm">Adjusting the Retargeted Mocap Data</a></span> for information. 
                  </p> 
               </div> 
               <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-0021"></a></span> 
                  <h3><span class="anchor_wrapper"><a name="GUID-8FEA1A70-D206-4272-B6C0-43407A2DDCEA"></a></span>Head Not Moving?
                  </h3> <span class="anchor_wrapper"><a name="UL_35535CE6357340BB8C0C35B30364AE72"></a></span><ul>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-2C3C2C82-7D71-4566-9774-2365345B4157"></a></span>If the head isn't moving but should be, it's probably because the head translation
                           and rotation are disabled in the Adjust property page by default. Simply activate
                           them and set the translation scale to 1 to get the full head translation. See <span class="char_link"><a href="face_act_AdjustingtheRetargetedMocapData.htm">Adjusting the Retargeted Mocap Data</a></span> for information. 
                        </p> 
                     </li>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-490E183D-0C09-42BE-BF26-D3E474A4AB04"></a></span>If the head still doesn't move, it could be that the mocap data you are using is stabilized,
                           meaning that the head translation and rotation have been filtered out of the mocap
                           clip. Use the unstabilized version if you want head motion. 
                        </p> 
                     </li>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-171551BB-F935-470C-8620-DE57FA23B1C0"></a></span>The last possibility is the mocap take has very little head motion: check your original
                           mocap clip to confirm this. 
                        </p> 
                     </li>
                  </ul> 
               </div> 
               <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-0022"></a></span> 
                  <h3><span class="anchor_wrapper"><a name="GUID-25EDF7B9-FDCF-4B65-A21E-4EC8A8BC9C2B"></a></span>Making Curves for the Mocap Data
                  </h3> <span class="anchor_wrapper"><a name="UL_931061C310EA4BCFA737C921A7E5A00E"></a></span><ul>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-7E03EF37-0EF9-4949-924D-554F230388D7"></a></span>You will notice that there are no visible keys or fcurves for the mocap. This is because
                           mocap is in a live retargeting mode until you bake it (plot it) into fcurves. This
                           lets you first make the adjustments to the mocap data before you make it final. 
                        </p> 
                     </li>
                     <li> 
                        <p><span class="anchor_wrapper"><a name="GUID-F2DA1444-2F4E-45D6-A26C-BF75E52DB2E1"></a></span>When you plot the motion capture data, the fcurves often have many keys, usually one
                           per frame. A high-density fcurve is difficult to edit because if you change even a
                           few keys, you have to adjust many other keys to retain the overall shape of the curve.
                           
                        </p> 
                     </li>
                  </ul> 
                  <p><span class="anchor_wrapper"><a name="GUID-D0A6A43A-0A01-499F-B9D1-16FBF712AB93"></a></span>See <span class="char_link"><a href="face_act_PlottingtheMocapandKeyframeData.htm">Plotting (Baking) the Mocap and Keyframe Data</a></span> for information. 
                  </p> 
               </div> 
               <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-0023"></a></span> 
                  <h3><span class="anchor_wrapper"><a name="GUID-5BE46F6B-9BB4-418A-B380-92E72B964E01"></a></span>Check the Jaw
                  </h3> 
                  <p><span class="anchor_wrapper"><a name="GUID-071575D7-4A11-4EF2-A459-CBB864D796E6"></a></span>Because there is no good way to capture the jaw motion with the skin sliding around
                     and affecting the markers, you may need to make adjustments to the jaw control in
                     order to compensate and keep the teeth the proper distance apart. You can do this
                     simply by keying the translation of the jaw control. Remember to key back to a neutral
                     pose at some point. Use a video reference and check the extreme poses and anywhere
                     that the teeth are supposed to be touching. 
                  </p> 
               </div> 
               <div class="section"><span class="anchor_wrapper"><a name="WSF468A8297860DD449B69C7615D16EBA9-0024"></a></span> 
                  <h3><span class="anchor_wrapper"><a name="GUID-87B6D9B8-9322-4C2C-B733-BBC2C92FBE27"></a></span>Fine-tune the Mouth Shapes
                  </h3> 
                  <p><span class="anchor_wrapper"><a name="GUID-40F19672-F4C9-41DC-9760-2DA456716870"></a></span>The most important parts of lip sync can't really be captured, so most of your time
                     will be spent addressing this. The interior shape of the lips, the way the fat bunches
                     up in the corners, the way the skin sticks together ... this stuff makes or breaks
                     realistic lip sync. The best way to get it right is to model the fixes with localized
                     shape animation. 
                  </p> 
               </div> 
            </div>
         </div>
         <div class="footer-block"><a href="../html/ac.cmtdialog.htm" class="comments-anchor" target="_blank"><span class="comments-link">Please send us your comment about this page</span></a></div><br><p class="footer-license-block"><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/" target="_blank"><img alt="Creative Commons License" style="border-width: 0;" src="../images/ccLink.png"></a>&nbsp;<em>Except where otherwise noted, this work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/" target="_blank">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>. Please see the <a href="http://autodesk.com/creativecommons" target="_blank">Autodesk Creative Commons FAQ</a> for more information.</em></p><br></div>
   </body>
</html>